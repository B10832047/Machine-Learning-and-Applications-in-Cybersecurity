#!/usr/bin/env python
# coding: utf-8

# In[2]:


from __future__ import print_function
import keras
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Concatenate
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Flatten, Dense, Lambda
from sklearn.model_selection import train_test_split
from siamese import SiameseNetwork
import numpy as np
from PIL import Image
import pandas as pd
import os
from sklearn.preprocessing import LabelEncoder
from generate_image import binary_to_image

# In[3]:


batch_size = 3
epochs = 20

# input image dimensions
input_shape = (256, 256, 3)

def create_base_model(input_shape):
    model_input = Input(shape=input_shape)

    embedding = Conv2D(32, kernel_size=(
        3, 3), input_shape=input_shape)(model_input)
    embedding = BatchNormalization()(embedding)
    embedding = Activation(activation='relu')(embedding)
    embedding = MaxPooling2D(pool_size=(2, 2))(embedding)
    embedding = Conv2D(64, kernel_size=(3, 3))(embedding)
    embedding = BatchNormalization()(embedding)
    embedding = Activation(activation='relu')(embedding)
    embedding = MaxPooling2D(pool_size=(2, 2))(embedding)
    embedding = Flatten()(embedding)
    embedding = Dense(128)(embedding)
    embedding = BatchNormalization()(embedding)
    embedding = Activation(activation='relu')(embedding)

    return Model(model_input, embedding)


def create_head_model(embedding_shape):
    embedding_a = Input(shape=embedding_shape[1:])
    embedding_b = Input(shape=embedding_shape[1:])
    L1_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))
    L1_distance = L1_layer([embedding_a, embedding_b])
    prediction = Dense(1, activation='sigmoid')(L1_distance)

    return Model([embedding_a, embedding_b], prediction)

if __name__ == '__main__':

    X, y = [], []
    files = os.listdir('malware')
    for file_name in files:
        save_path = os.path.join('img', 'malware', file_name)
        gem_image = binary_to_image('malware/'+ file_name)
        X += [gem_image]
    files = os.listdir('benign')
    for file_name in files:
        save_path = os.path.join('img', 'benign', file_name)
        gem_image = binary_to_image('benign/'+file_name)
        X += [gem_image]

    np.save('tmp', np.array(X))

    X, y = np.load('tmp.npy'), np.array([1 for i in range(50)] + [0 for i in range(50)])

    X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=777, test_size=0.9, shuffle=True)
    print(y_train, y_test)

    base_model = create_base_model(input_shape)
    head_model = create_head_model(base_model.output_shape)

    siamese_network = SiameseNetwork(base_model, head_model)
    siamese_network.compile(loss='binary_crossentropy',
                            optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])

    siamese_checkpoint_path = "./siamese_checkpoint"

    siamese_callbacks = [
        EarlyStopping(monitor='val_accuracy', patience=10, verbose=0),
        ModelCheckpoint(siamese_checkpoint_path,
                        monitor='val_accuracy', save_best_only=True, verbose=0)
    ]


    scores = []
    siamese_network.fit(X_train, y_train,
                        validation_data=(X_test, y_test),
                        batch_size=batch_size,
                        epochs=epochs,
                        callbacks=siamese_callbacks)
    score = siamese_network.evaluate(X_test, y_test, batch_size=batch_size)
    print('Test loss:', score[0])
    print('Test accuracy:', score[1])